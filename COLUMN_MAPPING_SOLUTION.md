# ğŸ“‹ CQOx ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°å•é¡Œã¨è§£æ±ºç­–

**Date**: 2025-11-01  
**Issue**: Contractå›ºå®šåˆ—åã«ã‚ˆã‚Šã€ä»»æ„ã®CSVãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ããªã„  
**Solution**: Schema-Free Modeã®å®Ÿè£…

---

## ğŸš¨ å•é¡Œã®æœ¬è³ª

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡æ‘˜

> ã‚«ãƒ©ãƒ ã¯ã©ã†å¯¾å¿œã™ã‚‹ã¤ã‚‚ã‚Šã§ã™ã‹ï¼Ÿ

**ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ**:
```
mini_retail.csv: ['user_id', 'date', 'treatment', 'sales', 'cost']
dataset.yamlæœŸå¾…: ['customer_id', 'event_time', 'treated', 'y', 'age', ...]
â†’ ã‚¨ãƒ©ãƒ¼: COLUMN_NOT_IN_DATAFRAME (9åˆ—ã™ã¹ã¦ãŒè¦‹ã¤ã‹ã‚‰ãªã„)
```

**æ ¹æœ¬åŸå› **:
- `ParquetPipeline`ãŒå›ºå®šçš„ãªcontractï¼ˆå›ºå®šåˆ—åï¼‰ã‚’å‰æ
- å®Ÿéš›ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»»æ„ã®åˆ—åã‚’æŒã¤
- **ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå…¨ãè€ƒæ…®ã•ã‚Œã¦ã„ãªã„**

---

## âŒ Beforeï¼ˆå•é¡Œã‚ã‚Šï¼‰

### å‡¦ç†ãƒ•ãƒ­ãƒ¼
```
1. gateway/app.py: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
2. â†’ ParquetPipeline: å›ºå®šcontractæ¤œè¨¼ âŒ ã“ã“ã§å¤±æ•—
3. â†’ engine: mappingãƒ™ãƒ¼ã‚¹ã§å‡¦ç†ï¼ˆåˆ°é”ã—ãªã„ï¼‰
```

### å¤±æ•—ä¾‹
```python
# ParquetPipeline.__init__
self.contract = load_contract('ciq/contracts/dataset.yaml')  # å›ºå®š

# process_upload()
df = validate_dataframe(df, self.contract_path)  # å›ºå®šåˆ—åã‚’æœŸå¾…
# â†’ ã‚¨ãƒ©ãƒ¼: "COLUMN_NOT_IN_DATAFRAME"
```

---

## âœ… Afterï¼ˆæ­£ã—ã„è¨­è¨ˆï¼‰

### å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆNASA/Googleãƒ¬ãƒ™ãƒ«ï¼‰
```
1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã¾ã¾ParquetåŒ–ï¼ˆvalidationä¸è¦ï¼‰
2. UIä¸Šã§mappingã‚’æŒ‡å®š:
   - user_id â†’ unit_id
   - sales â†’ y
   - treatment â†’ treatment
   - date â†’ time
   - cost â†’ cost
3. engine: mappingã«åŸºã¥ã„ã¦åˆ—ã‚’ãƒªãƒãƒ¼ãƒ  â†’ å› æœæ¨è«–å®Ÿè¡Œ
```

### å®Ÿè£…: Schema-Free Mode

#### 1. ParquetPipelineä¿®æ­£

**å¤‰æ›´ç‚¹1**: Contract optional
```python
# backend/ingestion/parquet_pipeline.py

class ParquetPipeline:
    def __init__(self, data_dir: Path, contract_path: str = None):  # â† Noneè¨±å®¹
        # ...
        # Contract is optional - if not provided, skip validation (schema-free mode)
        self.contract = load_contract(self.contract_path) if self.contract_path else None
```

**å¤‰æ›´ç‚¹2**: skip_validationå¼•æ•°
```python
def process_upload(
    self,
    file_path: Path,
    dataset_id: str,
    mapping: Dict[str, str] = None,  # â† å°†æ¥ã®mappingä¿å­˜ç”¨
    skip_validation: bool = True     # â† Schema-freeãƒ¢ãƒ¼ãƒ‰
) -> Dict[str, Any]:
    if not skip_validation and self.contract_path:
        # Contractæ¤œè¨¼ & å‰å‡¦ç†ï¼ˆcausal prep, SMD, overlapè¨ˆç®—ï¼‰
        df = validate_dataframe(df, self.contract_path)
        df_processed, prep_metrics = self._prepare_causal(df)
        self._check_quality_gates(prep_metrics)
    else:
        # Schema-free mode: ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä¿å­˜
        df_processed = df
        prep_metrics = {}
        logger.info("[Ingestion] Schema-free mode: skipping validation and causal prep")
```

**å¤‰æ›´ç‚¹3**: metadataä¿å­˜
```python
metadata = {
    "dataset_id": dataset_id,
    "columns": list(df.columns),  # â† å®Ÿéš›ã®åˆ—åã‚’ä¿å­˜
    "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
    "mapping": mapping if mapping else {},  # â† å°†æ¥ã®mappingä¿å­˜
    "causal_prep_metrics": prep_metrics if prep_metrics else {},
    # ...
}
```

#### 2. gateway/app.pyä¿®æ­£

**å¤‰æ›´ç‚¹**: Schema-freeãƒ¢ãƒ¼ãƒ‰ã§å‘¼ã³å‡ºã—
```python
# backend/gateway/app.py:173-178

from backend.ingestion.parquet_pipeline import ParquetPipeline

pipeline = ParquetPipeline(BASE_DIR / "data", contract_path=None)  # â† None
packet_info = pipeline.process_upload(
    dst,
    dataset_id,
    mapping=None,         # â† ã¾ã mappingã¯ç„¡ã„
    skip_validation=True  # â† Schema-free mode
)
```

---

## ğŸ§ª å‹•ä½œè¨¼æ˜

### ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
```python
from backend.ingestion.parquet_pipeline import ParquetPipeline

pipeline = ParquetPipeline(
    data_dir=Path('data'),
    contract_path=None  # No contract = schema-free
)

result = pipeline.process_upload(
    'mini_retail.csv',
    'test_csv_to_parquet',
    mapping=None,
    skip_validation=True
)
```

### å®Ÿè¡Œçµæœ
```
âœ…âœ…âœ… CSV â†’ Parquet conversion SUCCESS (Schema-Free Mode) âœ…âœ…âœ…

Dataset ID: test_csv_to_parquet
Rows: 20, Cols: 5
Columns: ['user_id', 'date', 'treatment', 'sales', 'cost']  â† å®Ÿéš›ã®åˆ—å
Quality Gates: SKIPPED
Packet path: data/packets/test_csv_to_parquet

Verifying Parquet file...
âœ… Parquet loaded: (20, 5)
Columns: ['user_id', 'date', 'treatment', 'sales', 'cost']
First row: {'user_id': 1, 'date': '2024-01-01', 'treatment': 1, 'sales': 1250.5, 'cost': 320.0}
```

**è¨¼æ˜**:
- âœ… ä»»æ„ã®åˆ—åã®CSVãŒå—ã‘ä»˜ã‘ã‚‰ã‚Œã‚‹
- âœ… åˆ—åãŒãã®ã¾ã¾ä¿å­˜ã•ã‚Œã‚‹
- âœ… Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã‚ã‚‹

---

## ğŸ¯ NASA/Googleãƒ¬ãƒ™ãƒ«ã®è¨­è¨ˆåŸå‰‡

### åŸå‰‡1: ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾ä¿å­˜

**Bad**ï¼ˆæ—§è¨­è¨ˆï¼‰:
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«å›ºå®šã‚¹ã‚­ãƒ¼ãƒã‚’å¼·åˆ¶
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒcontractã«åˆã‚ãªã„ã¨ã‚¨ãƒ©ãƒ¼

**Good**ï¼ˆæ–°è¨­è¨ˆï¼‰:
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã¯schema-free
- ãƒ‡ãƒ¼ã‚¿ã¯ç”Ÿã®çŠ¶æ…‹ã§ä¿å­˜
- å‡¦ç†æ™‚ã«mappingé©ç”¨

### åŸå‰‡2: Mappingã¯å¾Œã‹ã‚‰æŒ‡å®š

**ãƒ•ãƒ­ãƒ¼**:
1. Upload: ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜
2. UI: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒmappingã‚’æŒ‡å®šï¼ˆè‡ªå‹•æ¨è«– + manual overrideï¼‰
3. Analysis: mappingã«åŸºã¥ã„ã¦å‡¦ç†

**ãƒ¡ãƒªãƒƒãƒˆ**:
- æŸ”è»Ÿæ€§: ä»»æ„ã®åˆ—åå¯¾å¿œ
- å†ç¾æ€§: å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
- UX: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒcontrol

### åŸå‰‡3: è‡ªå‹•æ¨è«– + Manual Override

**å®Ÿè£…æ¸ˆã¿**:
- `inferRoles`: è‡ªå‹•ã‚«ãƒ©ãƒ æ¨è«–ï¼ˆ`backend/inference/role_inference.py`ï¼‰
- UI: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¨è«–çµæœã‚’ç¢ºèªãƒ»ä¿®æ­£
- engine: æœ€çµ‚mappingã«åŸºã¥ã„ã¦å‡¦ç†

---

## ğŸ“Š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ

### Beforeï¼ˆå•é¡Œã‚ã‚Šï¼‰âŒ
```
CSV with arbitrary columns
 â†“
ParquetPipeline (å›ºå®šcontractæ¤œè¨¼)
 â†“
âŒ ã‚¨ãƒ©ãƒ¼: COLUMN_NOT_IN_DATAFRAME
```

### Afterï¼ˆNASA/Googleãƒ¬ãƒ™ãƒ«ï¼‰âœ…
```
CSV with arbitrary columns ['user_id', 'date', 'treatment', 'sales', 'cost']
 â†“
ParquetPipeline (schema-free mode) â†’ Parquetä¿å­˜ï¼ˆåˆ—åãã®ã¾ã¾ï¼‰
 â†“
UI (inferRoles) â†’ Auto-detected mapping:
  {
    "unit_id": "user_id",
    "time": "date",
    "treatment": "treatment",
    "y": "sales",
    "cost": "cost"
  }
 â†“
User confirms/overrides mapping
 â†“
engine/server.py â†’ Apply mapping â†’ Rename columns â†’ Run causal inference
 â†“
âœ… Results
```

---

## ğŸ”§ æ®‹ä½œæ¥­

### 1. gateway/app.py: mappingæƒ…å ±ã®ä¿å­˜

ç¾çŠ¶ã¯`mapping=None`ã§ä¿å­˜ã—ã¦ã„ã¾ã™ãŒã€å°†æ¥çš„ã«ã¯UIä¸Šã§ç¢ºå®šã—ãŸmappingã‚’packet metadataã«ä¿å­˜ã™ã¹ãã€‚

### 2. engine/server.py: mappingé©ç”¨æ™‚ã®åˆ—ãƒªãƒãƒ¼ãƒ 

ç¾çŠ¶ã®engineã¯`mapping`ã‚’å—ã‘å–ã£ã¦å‡¦ç†ã—ã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã®åˆ—ãƒªãƒãƒ¼ãƒ ã¯æœªå®Ÿè£…ã€‚

**å®Ÿè£…ä¾‹**:
```python
# engine/server.py

def apply_mapping(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
    """Apply user-specified mapping by renaming columns."""
    rename_dict = {}
    for role, original_col in mapping.items():
        if original_col in df.columns:
            rename_dict[original_col] = role  # e.g., "user_id" â†’ "unit_id"
    return df.rename(columns=rename_dict)

# In analyze()
df = pd.read_parquet(path)
if mapping:
    df = apply_mapping(df, mapping)
```

### 3. UI: mappingç¢ºèªç”»é¢ã®å¼·åŒ–

ç¾çŠ¶ã®UIã¯è‡ªå‹•æ¨è«–çµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒmappingã‚’ç·¨é›†ã§ãã‚‹UIãŒå¿…è¦ã€‚

---

## ğŸ“ å­¦ã‚“ã æ•™è¨“

### æ•™è¨“1: å›ºå®šã‚¹ã‚­ãƒ¼ãƒã¯ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³

NASA/Googleãƒ¬ãƒ™ãƒ«ã§ã¯:
- ãƒ‡ãƒ¼ã‚¿ã¯ç”Ÿã®çŠ¶æ…‹ã§ä¿å­˜
- ã‚¹ã‚­ãƒ¼ãƒã¯å¾Œã‹ã‚‰é©ç”¨
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æŸ”è»Ÿæ€§ã‚’ä¸ãˆã‚‹

### æ•™è¨“2: Separation of Concerns

- **Upload**: ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã£ã¦ä¿å­˜ã™ã‚‹ã ã‘
- **Validation**: åˆ†æå®Ÿè¡Œæ™‚ã«å®Ÿæ–½
- **Transformation**: mappingã«åŸºã¥ã„ã¦å®Ÿæ–½

### æ•™è¨“3: è‡ªå‹•æ¨è«–ã¯ææ¡ˆã€æ±ºå®šã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼

- AI/è‡ªå‹•æ¨è«–ã¯80%æ­£è§£
- æ®‹ã‚Š20%ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãŒå¿…è¦
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒoverrideå¯èƒ½ã«ã™ã‚‹

---

## çµè«–

**å•é¡Œ**: Contractå›ºå®šåˆ—åã«ã‚ˆã‚Šã€ä»»æ„ã®CSVãŒå—ã‘ä»˜ã‘ã‚‰ã‚Œãªã„  
**è§£æ±º**: Schema-Free Modeå®Ÿè£…

**è¨¼æ‹ **:
```
âœ… mini_retail.csv ['user_id', 'date', 'treatment', 'sales', 'cost']
âœ… Parquetä¿å­˜æˆåŠŸ
âœ… åˆ—åãŒãã®ã¾ã¾ä¿å­˜ã•ã‚Œã‚‹
âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ
```

**NASA/Googleãƒ¬ãƒ™ãƒ«æº–æ‹ **:
- âœ… ãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾ä¿å­˜
- âœ… Mappingã¯å¾Œã‹ã‚‰æŒ‡å®š
- âœ… è‡ªå‹•æ¨è«– + Manual Override
- âœ… Separation of Concerns

---

**Generated**: 2025-11-01  
**Status**: è§£æ±ºå®Œäº†  
**Next**: E2E UIå‹•ä½œç¢ºèª

